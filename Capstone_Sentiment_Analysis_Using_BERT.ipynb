{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEUs4Gan6Nk_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH3Cgny06hIl"
      },
      "source": [
        "You are the lead Data Scientist for Pharmaceutical company Kipla, they have collected comments for various products scraping from various online sources and wish to create a sentiment analysis engine that can track the sentiment regarding a specified drug from 3 categories namely positive negative and neutral. Every sample will contain the text mentioning a drug name and the comment pertaining to it. Multiple products could be there within a single comment\n",
        "\n",
        "\n",
        "\n",
        "Example\n",
        "\n",
        "I looked up stomach pain after taking Correctol...and here I am, wishing I had read these comments before I took it. I'm sitting here with the worst stomach pain I've had since labor. I feel like I need to vomit but have dry mouth. My intestines feel like someone is twisting them.ive honestly been sitting on the toilet for an hour and no bm...just severe abdominal pain and I vomited once. I will NEVER take this medication again! Post that I took Meftal Spas and it worked wonders for me.\n",
        "\n",
        "\n",
        "\n",
        "Now this comment is positive for Meftal Spas medicine but negative for Correctol.\n",
        "\n",
        "Evaluation Metric\n",
        "The metric used for evaluating the performance of the classification model would be macro F1-Score.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz8ER0I76m_Z",
        "outputId": "51cf14e3-9c2b-43e1-f37b-7cb07d520eb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#import torch library\n",
        "import torch\n",
        "\n",
        "# check GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    # select GPU\n",
        "    device = torch.device(\"cuda\")\n",
        "else: # If no GPU is available, use CPU\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3izxOAzC7Dim",
        "outputId": "65cc00b0-ce8c-45d2-aeb1-b943e858cf89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# check GPU name\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVgT3eZy7Iqr"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# Load BERT-base-uncased\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KmAhd9ki8guq",
        "outputId": "2a84764f-eb4d-4dee-b279-75239b315d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# print bert architecture\n",
        "print(bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ycxDTq08jfD",
        "outputId": "64d1e039-495e-4643-8313-ac88e3ab00f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Download BERT Tokenizer\n",
        "#importing fast \"BERT\" tokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJcCkXDz8sh3",
        "outputId": "afffea9a-7773-4254-8075-1cf78eb30044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer Sequence: [101, 3958, 2003, 1037, 15610, 102, 0, 0, 0, 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "text = 'Jim is a waiter'\n",
        "sent_id = tokenizer.encode(text,\n",
        "                           # add [CLS] and [SEP] tokens\n",
        "                           add_special_tokens=True,\n",
        "                           # specify maximum length for the sequences\n",
        "                           max_length = 10,\n",
        "                           truncation = True,\n",
        "                           # add pad tokens to the right side of the sequence\n",
        "                           pad_to_max_length='right')\n",
        "\n",
        "# print integer sequence\n",
        "print(\"Integer Sequence: {}\".format(sent_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M-_ZPOSAk-3",
        "outputId": "08bb44f3-3781-4f8f-e260-bc6660e115b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Mask: [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "# mask to avoid performing attention on padding token indices.\n",
        "# mask values: 1 for tokens that are NOT MASKED, 0 for MASKED tokens.\n",
        "att_mask = [int(tok > 0) for tok in sent_id]\n",
        "\n",
        "print(\"Attention Mask:\",att_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMC00jwYAqTM",
        "outputId": "3977c9d9-139d-49f9-8401-099aedbdbd70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  3958,  2003,  1037, 15610,   102,     0,     0,     0,     0]])\n"
          ]
        }
      ],
      "source": [
        "# convert lists to tensors\n",
        "sent_id = torch.tensor(sent_id)\n",
        "att_mask = torch.tensor(att_mask)\n",
        "\n",
        "# reshaping tensor in form of (batch,text length)\n",
        "sent_id = sent_id.unsqueeze(0)\n",
        "att_mask = att_mask.unsqueeze(0)\n",
        "\n",
        "# reshaped tensor\n",
        "print(sent_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dRqB0zvBPff"
      },
      "outputs": [],
      "source": [
        "# pass integer sequence to bert model\n",
        "outputs = bert(sent_id, attention_mask=att_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJtfPEeKBSPK",
        "outputId": "054fb38e-0221-4f74-810a-e9f6929682b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of last hidden states: torch.Size([1, 10, 768])\n",
            "Shape of CLS hidden state: torch.Size([1, 768])\n"
          ]
        }
      ],
      "source": [
        "## unpack the ouput of bert model\n",
        "# hidden states at each timestep\n",
        "all_hidden_states = outputs[0]\n",
        "# hidden states at first timestep ([CLS] token)\n",
        "cls_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of last hidden states:\",all_hidden_states.shape)\n",
        "print(\"Shape of CLS hidden state:\",cls_hidden_state.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0PM07NJbBanZ",
        "outputId": "f496a3b8-007c-44ea-e6e1-603b5dea7575"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                unique_hash  \\\n",
              "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0   \n",
              "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4   \n",
              "2  fe809672251f6bd0d986e00380f48d047c7e7b76   \n",
              "3  bd22104dfa9ec80db4099523e03fae7a52735eb6   \n",
              "4  b227688381f9b25e5b65109dd00f7f895e838249   \n",
              "\n",
              "                                                text        drug  sentiment  \n",
              "0  Autoimmune diseases tend to come in clusters. ...     gilenya          2  \n",
              "1  I can completely understand why you’d want to ...     gilenya          2  \n",
              "2  Interesting that it only targets S1P-1/5 recep...  fingolimod          2  \n",
              "3  Very interesting, grand merci. Now I wonder wh...     ocrevus          2  \n",
              "4  Hi everybody, My latest MRI results for Brain ...     gilenya          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e764844-a47f-4caa-86b2-d10de0c68b40\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
              "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
              "      <td>I can completely understand why you’d want to ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
              "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
              "      <td>fingolimod</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
              "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
              "      <td>ocrevus</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
              "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e764844-a47f-4caa-86b2-d10de0c68b40')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e764844-a47f-4caa-86b2-d10de0c68b40 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e764844-a47f-4caa-86b2-d10de0c68b40');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c39d8cb-a390-4cd6-a25b-619c677dcdd2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c39d8cb-a390-4cd6-a25b-619c677dcdd2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c39d8cb-a390-4cd6-a25b-619c677dcdd2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5279,\n  \"fields\": [\n    {\n      \"column\": \"unique_hash\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5279,\n        \"samples\": [\n          \"8fd3d7ad80791c9343e5cf8a83bd1adf6577d516\",\n          \"75b70aebd619b83228d73da1df1d0b0acc56af57\",\n          \"e2a45e96162496ec79648764a2153696cf0358a8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5181,\n        \"samples\": [\n          \"Long-term use may raise your chance of cancer. Lymphoma and other cancers have happened in people who take Imuran (azathioprine tablets) or drugs like it. This has been deadly in some cases. Talk with the doctor. A rare type of cancer called hepatosplenic T-cell lymphoma (HSTCL) has happened with Imuran (azathioprine tablets). These cases have been deadly. Most of the time, these cases happened in teenagers or young adults. Most of these patients were using Imuran (azathioprine tablets) to treat certain types of bowel problems like Crohn disease and  ulcerative colitis . This medicine is not approved for use to treat bowel problems like these. Tell the doctor if you have ever had any type of cancer. Talk with the doctor.  Uses of Imuran: See also: Entyvio It is used to keep the body from turning down the kidney after a kidney transplant . It is used to treat rheumatoid arthritis . It may be given to you for other reasons. Talk with the doctor.  What do I need to tell my doctor BEFORE I take Imuran? For all uses of Imuran (azathioprine tablets): If you have an allergy to azathioprine or any other part of Imuran (azathioprine tablets). If you are allergic to any drugs like this one, any other drugs, foods, or other substances. Tell your doctor about the allergy and what signs you had, like rash; hives ; itching; shortness of breath; wheezing; cough; swelling of face, lips, tongue, or throat; or any other signs. If you have ever been treated with chlorambucil , cyclosporine , or melphalan in the past. If you are breast-feeding or plan to breast-feed. Rheumatoid arthritis patients: If you are pregnant or may be pregnant. Do not take Imuran (azathioprine tablets) if you are pregnant. This is not a list of all drugs or health problems that interact with Imuran (azathioprine tablets). Tell your doctor and pharmacist about all of your drugs (prescription or OTC, natural products,  vitamins ) and health problems. You must check to make sure that it is safe for you to take Imuran (azathioprine tablets) with all of your drugs and health problems. Do not start, stop, or change the dose of any drug without checking with your doctor.  What are some things I need to know or do while I take Imuran? Tell all of your health care providers that you take Imuran (azathioprine tablets). This includes your doctors, nurses, pharmacists, and dentists. You may have more of a chance of getting an infection. Wash hands often. Stay away from people with infections, colds, or flu. Some infections have been very bad and even deadly. You may bleed more easily. Be careful and avoid injury. Use a soft toothbrush and an electric razor. If you have a thiopurine methyltransferase deficiency, talk with your doctor. Have blood work checked as you have been told by the doctor. Talk with the doctor. The chance of skin cancer may be raised. Avoid lots of sun, sunlamps, and tanning beds. Use sunscreen and wear clothing and eyewear that protects you from the sun. You may need to have your skin checked while you take Imuran (azathioprine tablets). Talk with your doctor. Talk with your doctor before getting any vaccines. Use with Imuran (azathioprine tablets) may either raise the chance of an infection or make the vaccine not work as well. If you are taking warfarin , talk with your doctor. You may need to have your blood work checked more closely while you are taking it with Imuran (azathioprine tablets). This medicine may cause harm to the unborn baby if you take it while you are pregnant. Use birth control that you can trust to prevent pregnancy while taking Imuran (azathioprine tablets). If you are pregnant or you get pregnant while taking Imuran (azathioprine tablets), call your doctor right away.  How is this medicine (Imuran) best taken? Use Imuran (azathioprine tablets) as ordered by your doctor. Read all information given to you. Follow all instructions closely. Take after meals unless your doctor says otherwise. To gain the most benefit, do not miss doses. Keep taking Imuran (azathioprine tablets) as you have been told by your doctor or other health care provider, even if you feel well.  What do I do if I miss a dose? Take a missed dose as soon as you think about it. If it is close to the time for your next dose, skip the missed dose and go back to your normal time. Do not take 2 doses at the same time or extra doses.  See also: Dosage Information (in more detail) What are some side effects that I need to call my doctor about right away? WARNING/CAUTION: Even though it may be rare, some people may have very bad and sometimes deadly side effects when taking a drug. Tell your doctor or get medical help right away if you have any of the following signs or symptoms that may be related to a very bad side effect: Signs of an allergic reaction, like rash; hives; itching; red, swollen, blistered, or peeling skin with or without fever; wheezing; tightness in the chest or throat; trouble breathing, swallowing, or talking; unusual hoarseness; or swelling of the mouth, face, lips, tongue, or throat. Signs of infection like fever, chills, very bad sore throat , ear or sinus pain, cough, more sputum or change in color of sputum, pain with passing urine, mouth sores, or wound that will not heal. Signs of bleeding like throwing up blood or throw up that looks like coffee grounds; coughing up blood ; blood in the urine; black, red, or tarry stools; bleeding from the gums; vaginal bleeding that is not normal; bruises without a reason or that get bigger; or any bleeding that is very bad or that you cannot stop. Signs of liver problems like dark urine, feeling tired, not hungry, upset stomach or stomach pain, light-colored stools, throwing up, or yellow skin or eyes. Signs of a pancreas problem ( pancreatitis ) like very bad stomach pain, very bad back pain , or very bad upset stomach or throwing up. Chest pain or pressure. Very upset stomach or throwing up. Feeling very tired or weak. Very bad dizziness or passing out. Loose stools ( diarrhea ). Muscle pain or weakness. Night sweats . A big weight loss . Fever that does not go away. Change in color or size of a mole. A skin lump or growth. A very bad brain problem called progressive multifocal leukoencephalopathy (PML) has happened with Imuran (azathioprine tablets). It may cause disability or can be deadly. Tell your doctor right away if you have signs like confusion, memory problems, low mood ( depression ), change in the way you act, change in strength on 1 side is greater than the other, trouble speaking or thinking, change in balance, or change in eyesight.  What are some other side effects of Imuran? All drugs may cause side effects. However, many people have no side effects or only have minor side effects. Call your doctor or get medical help if any of these side effects or any other side effects bother you or do not go away: Upset stomach or throwing up. These are not all of the side effects that may occur. If you have questions about side effects, call your doctor. Call your doctor for medical advice about side effects. You may report side effects to the FDA at 1-800-FDA-1088. You may also report side effects at http://www.fda.gov/medwatch.  See also: Side effects (in more detail) If OVERDOSE is suspected: If you think there has been an overdose, call your poison control center or get medical care right away. Be ready to tell or show what was taken, how much, and when it happened.  How do I store and/or throw out Imuran? Store at room temperature. Store in a dry place. Do not store in a bathroom. Protect from light. Keep all drugs in a safe place. Keep all drugs out of the reach of children and pets. Throw away unused or expired drugs. Do not flush down a toilet or pour down a drain unless you are told to do so. Check with your pharmacist if you have questions about the best way to throw out drugs. There may be drug take-back programs in your area.  Consumer information use If your symptoms or health problems do not get better or if they become worse, call your doctor. Do not share your drugs with others and do not take anyone else's drugs. Keep a list of all your drugs (prescription, natural products, vitamins , OTC) with you. Give this list to your doctor. Talk with the doctor before starting any new drug, including prescription or OTC, natural products, or vitamins . Some drugs may have another patient information leaflet. Check with your pharmacist. If you have any questions about Imuran (azathioprine tablets), please talk with your doctor, nurse, pharmacist, or other health care provider. If you think there has been an overdose, call your poison control center or get medical care right away. Be ready to tell or show what was taken, how much, and when it happened.\",\n          \"Not mildly effective...based on the outcomes distinctly negative. There was a positive trial on spasticity just not mine. As for ECTRIMS every 5 years...No. The purpose of ECTRIMS is to keep your neurologists up to date. If there are no new treatments so be it, however ocrelizumab is new since last year and neurologists need to be informed about it. They have to undertake so many hours of training each year to keep current. Maybe I will give you my take on the MS SMART study, but today is not that time. ProfG may give you a round up once he has had a rest, he has been very bust ths week as usual. There are a number of positives that we can take from this.\",\n          \"Hi  Dane life \\u200d , welcome to the forum. I was diagnosed with lung cancer in April but due to delays at the lab it took until the end of June before the oncologist decided to put me on keytruda. I had the third treatment a week ago. There have been no serious side effects so far. I am a little more tired , weaker and mild joint pain occasionally. I cough up a lot of fluid but Dr. says that's the tumor/cancer causing this not the keytruda. My appetite has been good-even putting on weight. I have no problem driving 3 hours for treatment. Good luck on your journey with us.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"drug\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 102,\n        \"samples\": [\n          \"atezolizumab\",\n          \"pf-00547659\",\n          \"imfinzi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# upload the data and extract the file\n",
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5DGdSaeC-Mv",
        "outputId": "dc7fa175-71de-41e2-ca44-50e93e67e103"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5279, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#shape of the dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "ZolJP8JfHvw2",
        "outputId": "420c4127-7386-4f37-c7f6-92c2ba6f67d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "2    3825\n",
              "1     837\n",
              "0     617\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>617</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# class distribution\n",
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "d7i46q8nH02c",
        "outputId": "6f13b045-3d5b-4667-aaa7-0e9f271a3f98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "2    0.724569\n",
              "1    0.158553\n",
              "0    0.116878\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.724569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.158553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.116878</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# class distribution\n",
        "df['sentiment'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZtzUmLiH6px"
      },
      "outputs": [],
      "source": [
        "# saving the value counts to a list\n",
        "class_counts = df['sentiment'].value_counts().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKV9FhvzNOPA",
        "outputId": "1c91980b-92b6-4bdd-a0f1-37a94f6c0f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'on', 'too', 'weren', 's', 'yours', \"shan't\", \"wouldn't\", 'not', 'just', 'hadn', 'll', 'is', 'between', 'doesn', 'mightn', 'hasn', 'y', 'below', 'own', 'am', 'only', 'ain', 'had', 'shouldn', 'before', 'of', 'yourselves', 'didn', \"you've\", 'which', \"should've\", 'from', 'our', 'off', 'where', 'itself', 'should', \"you're\", 'd', 'why', 'his', 'ours', 'being', 'be', 'few', 'out', 'while', 'needn', 'wouldn', 'other', 'those', 'has', 'o', 'how', \"aren't\", \"hadn't\", 'its', 'this', 'an', 'shan', 'these', 'very', 'what', 'do', 'them', 'they', 'when', 'until', 'whom', 'was', 'into', \"isn't\", 'down', 'hers', \"needn't\", \"you'll\", \"it's\", 'then', 'a', 'who', \"doesn't\", 'himself', 'for', 'most', 'couldn', 'won', 'her', 'aren', 'and', 'theirs', 'because', 'your', 'their', 'you', 'mustn', 'to', 'or', 'by', 'each', 'does', 'are', 'in', 'here', 'both', 'me', \"mightn't\", 'no', 'all', 'above', \"haven't\", 'wasn', \"don't\", 'she', 'were', 'that', 'herself', 'the', 'against', 'if', \"mustn't\", \"couldn't\", 'once', 'about', 'don', 'm', 'at', \"shouldn't\", 'again', 'we', 'yourself', 'during', 'haven', \"won't\", 'doing', 'than', 't', 'so', 'isn', 'there', \"that'll\", 'through', 'ma', 'as', 'further', 'with', 'after', 'up', \"hasn't\", 'same', 'did', \"didn't\", 'under', 'any', 'him', 'themselves', 'will', 've', \"she's\", 'i', 'myself', 'some', 'been', 'can', \"you'd\", 'having', 'such', 'it', 'now', \"weren't\", 'nor', \"wasn't\", 'over', 'he', 'but', 'more', 're', 'my', 'have', 'ourselves'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the stopwords data if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the list of English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IND52HXlRbxd",
        "outputId": "1f68a03c-851c-46f9-abd1-65e06c0525b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoVU0jmhOsJ-",
        "outputId": "2239f27f-30a2-407b-c46a-d04205e440b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILhVFR3aIJqT",
        "outputId": "f22e4fe9-2e83-45bb-9963-efaa022fef37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions\n",
        "import re\n",
        "import contractions\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "# Initialize stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocessor(text):\n",
        "    # Expand contractions\n",
        "    text = contractions.fix(text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Replace numbers\n",
        "    text = re.sub(r'\\d+', '<num>', text)\n",
        "\n",
        "    # Replace emails and mentions\n",
        "    text = re.sub(r'\\S+@\\S+', '<email>', text)  # replace emails with <email>\n",
        "    text = re.sub(r'@\\w+', '<mention>', text)   # replace mentions with <mention>\n",
        "\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "    # Removes emojis and certain symbols\n",
        "    text = re.sub(r'[^\\w\\s,]', '', text)\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Replace numbers with a placeholder\n",
        "    text = re.sub(r'\\d+', '<num>', text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatize tokens\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', \" \".join(tokens)).strip()\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8P39R7EnM351"
      },
      "outputs": [],
      "source": [
        "# perform text cleaning\n",
        "df['clean_text']= df['text'].apply(preprocessor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAggepWbNyJI"
      },
      "outputs": [],
      "source": [
        "# save cleaned text and labels to a variable\n",
        "text   = df['clean_text'].values\n",
        "labels = df['sentiment'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "XMULejRWQPz5",
        "outputId": "abc2eb72-a873-4c18-d31c-23d5e85815ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Preparing Input Data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute the number of words in each tweet\n",
        "num = [len(i.split()) for i in text]\n",
        "\n",
        "# Plot the histogram with a limit on the x-axis\n",
        "plt.hist(num, bins=30)\n",
        "\n",
        "plt.title(\"Histogram: Length of sentences\")\n",
        "plt.xlabel(\"Number of Words\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "# Set the x-axis limit to 1000\n",
        "plt.xlim(0, 1000)  # You can adjust this value based on your actual data range\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wska7m3TWg8"
      },
      "outputs": [],
      "source": [
        "# Majority of the clean text  are concentrated around 400 words at most.\n",
        "# define maximum length of a text\n",
        "max_len = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "71df7a084c6a4c438c02ccd0854c0f53",
            "3548548d8d494297bd1ba729d3e7769b",
            "b401a3e63d1d40c29b3f89297dfa9b0e",
            "315691cab3134145830f41eada8a0a78",
            "dfae2fce887e407eafc97e1685dd541c",
            "c1bb6bd6c22c4df4bbfeedf8dbf27f3f",
            "18a0874dfec14ea090dc1ac7f5380370",
            "99e9dee44f574e31b6942d44fd27d19b",
            "962f96b0369141bd93f33a2fd0eb4527",
            "03da03df17b34177878828645ccffc91",
            "9a2b0ff1afaf4bd097efaf9fece6d62b"
          ]
        },
        "id": "de0ZDhHkEkGv",
        "outputId": "14853c4d-803b-4e0b-b6d2-850a26a94c14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5279 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71df7a084c6a4c438c02ccd0854c0f53"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# library for progress bar\n",
        "from tqdm import notebook\n",
        "\n",
        "# create an empty list to save integer sequence\n",
        "sent_id = []\n",
        "\n",
        "# iterate over each feedback\n",
        "for i in notebook.tqdm(range(len(text))):\n",
        "\n",
        "  encoded_sent = tokenizer.encode(text[i],\n",
        "                                  add_special_tokens = True,\n",
        "                                  max_length = max_len,\n",
        "                                  truncation = True,\n",
        "                                  padding = 'max_length')\n",
        "\n",
        "  # saving integer sequence to a list\n",
        "  sent_id.append(encoded_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ViDxWxJE-4h",
        "outputId": "7064c93f-ead0-4345-c5f1-d583bf601007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer Sequence: [101, 8285, 5714, 23041, 2063, 4295, 7166, 2272, 9324, 2004, 13097, 2368, 3148, 2514, 2204, 2228, 2689, 2505, 5949, 2051, 2943, 1045, 2635, 5939, 3736, 23736, 2514, 6429, 25353, 27718, 5358, 26489, 6292, 3609, 4432, 1045, 2144, 2467, 2113, 1045, 2113, 2197, 3204, 2095, 5476, 2787, 5959, 4536, 2391, 15366, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(\"Integer Sequence:\",sent_id[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8hIkj-UFB8U"
      },
      "outputs": [],
      "source": [
        "# create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# for each sentence...\n",
        "for sent in sent_id:\n",
        "  att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "  # store the attention mask for this sentence\n",
        "  attention_masks.append(att_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YWrmwdgFCMa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#Preparing Output\n",
        "labels = np.array(df['sentiment'])\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets (90% train, 10% validation)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
        "    sent_id, labels, random_state=2018, test_size=0.1, stratify=labels)\n",
        "\n",
        "# Split the attention masks in the same way\n",
        "train_masks, validation_masks, _, _ = train_test_split(\n",
        "    attention_masks, labels, random_state=2018, test_size=0.1, stratify=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FyYu1yCFCPb"
      },
      "outputs": [],
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8aRMfWML4ru"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "#Dataset wrapping tensors.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "#define a sampler for sampling the data during training\n",
        "  #random sampler samples randomly from a dataset\n",
        "  #sequential sampler samples sequentially, always in the same order\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "#represents a iterator over a dataset. Supports batching, customized data loading order\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "#Dataset wrapping tensors.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "\n",
        "#define a sequential sampler\n",
        "#This samples data in a sequential order\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "\n",
        "#create a iterator over the dataset\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BuFBO9LM5t0"
      },
      "outputs": [],
      "source": [
        "#create an iterator object\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "# Load the batch data\n",
        "sent_id, mask, target = next(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t04BkYOYRYjL",
        "outputId": "740d1786-9367-46a2-98cf-cb357b283262"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "sent_id.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN9X3zSJRrK5",
        "outputId": "3795b9cb-23c2-4f72-ac8e-e242f6dfd45e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101, 16697, 13551,  ...,     0,     0,     0],\n",
              "        [  101,  4067,  2017,  ...,     0,     0,     0],\n",
              "        [  101,  3081,  4684,  ...,  2147,  3204,   102],\n",
              "        ...,\n",
              "        [  101,  1045,  2657,  ...,  5796, 20014,   102],\n",
              "        [  101,  7632,  1045,  ...,     0,     0,     0],\n",
              "        [  101,  5254,  1045,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "sent_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esi-iVMXRtvq"
      },
      "outputs": [],
      "source": [
        "#pass inputs to the model\n",
        "outputs = bert(sent_id,             #integer sequence\n",
        "               attention_mask=mask) #attention masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd1glvMsRxrm",
        "outputId": "c94c3222-76a7-4128-9def-239786efb524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Hidden States: torch.Size([16, 300, 768])\n",
            "Shape of CLS Hidden State: torch.Size([16, 768])\n"
          ]
        }
      ],
      "source": [
        "# hidden states\n",
        "hidden_states = outputs[0]\n",
        "\n",
        "# [CLS] hidden state\n",
        "CLS_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of Hidden States:\",hidden_states.shape)\n",
        "print(\"Shape of CLS Hidden State:\",CLS_hidden_state.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrUzeaI8R0C4"
      },
      "outputs": [],
      "source": [
        "#4. Model Finetuning\n",
        "# turn off the gradient of all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3XHELHgJmI5"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "\n",
        "    #define the layers and wrappers used by model\n",
        "    def __init__(self, bert):\n",
        "\n",
        "      #constructor\n",
        "      super(classifier, self).__init__()\n",
        "\n",
        "      #bert model\n",
        "      self.bert = bert\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "      #dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,3)\n",
        "\n",
        "      #dropout layer\n",
        "      self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "      #relu activation function\n",
        "      self.relu =  nn.LeakyReLU()\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "#define the forward pass\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model\n",
        "      outputs = self.bert(sent_id, attention_mask=mask)\n",
        "\n",
        "      # Check the type and content of outputs to understand its structure\n",
        "      print(type(outputs))\n",
        "      print(outputs)\n",
        "\n",
        "      # Access the hidden states based on the structure of outputs\n",
        "      # For example, if outputs is a tuple and the hidden states are the first element:\n",
        "      all_hidden_states = outputs.last_hidden_state\n",
        "\n",
        "      # Extract the first token's hidden state (CLS token)\n",
        "      cls_hidden_state= all_hidden_states[:, 0]\n",
        "\n",
        "     #pass CLS hidden state to dense layer\n",
        "      x = self.fc1(cls_hidden_state)\n",
        "\n",
        "      #Apply ReLU activation function\n",
        "      x = self.relu(x)\n",
        "\n",
        "      #Apply Dropout\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      #pass input to the output layer\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      #apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqascKj7SUOy"
      },
      "outputs": [],
      "source": [
        "#create the model\n",
        "model = classifier(bert)\n",
        "\n",
        "#push the model to GPU, if available\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tvj5xdtZSUVt",
        "outputId": "fc59302c-065e-4b68-b29e-345126944a74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (relu): LeakyReLU(negative_slope=0.01)\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "#model architecture\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G9S-cyuvSUZJ",
        "outputId": "26f09a0c-517d-494d-afca-1b21108a6f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>\n",
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-2.2391e-01,  2.1971e-01,  6.5904e-02,  ..., -1.5012e-01,\n",
            "           9.6783e-02,  1.2138e-01],\n",
            "         [-1.4222e-01,  3.1666e-01, -2.2605e-02,  ..., -2.1713e-01,\n",
            "          -1.6049e-01,  9.8657e-03],\n",
            "         [ 8.6462e-03,  1.3960e-01,  2.2869e-01,  ..., -3.7254e-01,\n",
            "           2.6435e-01, -2.6977e-01],\n",
            "         ...,\n",
            "         [-3.3565e-01, -5.0305e-01,  6.0329e-01,  ...,  7.4293e-02,\n",
            "          -6.7794e-02,  1.9734e-01],\n",
            "         [-9.9674e-02, -9.4391e-02,  2.0794e-01,  ..., -1.2860e-01,\n",
            "           2.3371e-01,  1.7619e-01],\n",
            "         [ 6.4535e-02, -4.8112e-03,  3.6211e-01,  ...,  7.0497e-02,\n",
            "           1.0885e-01,  1.2460e-01]],\n",
            "\n",
            "        [[-2.2973e-01,  3.0387e-01,  3.9412e-01,  ..., -3.5555e-01,\n",
            "           5.0527e-02,  1.2463e-01],\n",
            "         [ 4.1392e-01,  5.3275e-01,  1.1848e+00,  ..., -1.4039e-01,\n",
            "           1.3748e-01,  3.5266e-01],\n",
            "         [-2.8931e-01, -2.1315e-01,  1.5658e+00,  ...,  1.4525e-01,\n",
            "           3.0162e-01, -5.0616e-01],\n",
            "         ...,\n",
            "         [ 3.2405e-01, -6.5882e-01,  4.9599e-01,  ..., -4.6042e-01,\n",
            "           3.4840e-01, -1.8840e-01],\n",
            "         [-2.5699e-02,  1.0618e-01,  2.3405e-01,  ..., -3.4266e-01,\n",
            "           1.0331e-01,  2.0938e-01],\n",
            "         [ 1.3509e-01,  1.8497e-01,  6.5568e-01,  ..., -5.6198e-01,\n",
            "           3.5086e-01,  1.7955e-01]],\n",
            "\n",
            "        [[-1.1447e-01, -5.9164e-02,  2.1497e-01,  ..., -4.2954e-01,\n",
            "           2.8745e-03, -1.3737e-01],\n",
            "         [ 6.4798e-01,  3.6494e-01,  1.2703e+00,  ..., -2.8667e-01,\n",
            "           6.5066e-01,  6.3865e-01],\n",
            "         [ 9.9707e-02,  1.0234e-01,  1.4714e+00,  ..., -5.5233e-01,\n",
            "          -3.1617e-01, -6.5109e-02],\n",
            "         ...,\n",
            "         [ 6.6624e-02,  3.4124e-01,  6.4611e-01,  ..., -1.6997e-01,\n",
            "           3.4278e-01, -8.0464e-01],\n",
            "         [-9.0614e-01, -6.2251e-01,  6.5178e-01,  ...,  3.2504e-01,\n",
            "          -8.3053e-02, -8.1358e-01],\n",
            "         [ 2.9179e-01,  1.4286e-01,  4.4230e-02,  ..., -1.2727e-01,\n",
            "          -1.6411e-01,  1.5044e-03]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-2.6274e-01, -4.5809e-01,  2.6044e-01,  ..., -2.4239e-01,\n",
            "           6.3349e-02,  2.6376e-01],\n",
            "         [ 3.2428e-01, -3.8956e-01,  4.5584e-01,  ..., -1.1837e-01,\n",
            "           1.4356e+00, -3.2762e-01],\n",
            "         [-6.0141e-01, -2.4113e-01,  1.2590e+00,  ..., -3.5722e-01,\n",
            "          -2.1749e-01, -3.6774e-01],\n",
            "         ...,\n",
            "         [-6.7331e-01,  1.4695e-01,  8.4895e-01,  ..., -2.9276e-02,\n",
            "          -5.3115e-01,  3.8032e-01],\n",
            "         [-7.7957e-01, -1.1544e+00, -1.7357e-01,  ...,  6.9100e-02,\n",
            "          -3.0272e-01, -5.9869e-01],\n",
            "         [ 5.4078e-01,  1.1656e-01,  2.2785e-01,  ...,  3.9375e-02,\n",
            "          -1.6982e-01, -1.7099e-01]],\n",
            "\n",
            "        [[ 2.3628e-02, -7.4275e-02,  5.2555e-01,  ..., -4.3501e-01,\n",
            "           2.3764e-01,  2.4968e-01],\n",
            "         [ 3.2861e-01, -2.9049e-01,  1.3053e+00,  ..., -3.1015e-01,\n",
            "           8.7916e-02, -6.1320e-01],\n",
            "         [-6.5264e-02, -5.6087e-01,  6.6830e-01,  ..., -2.3803e-01,\n",
            "           3.8198e-01,  2.1471e-01],\n",
            "         ...,\n",
            "         [ 1.0178e-01, -1.4316e-01,  4.1252e-01,  ..., -8.8198e-02,\n",
            "           1.1093e-02,  3.1223e-02],\n",
            "         [ 2.2182e-01, -1.4983e-01,  3.6558e-01,  ..., -1.6514e-01,\n",
            "          -6.1754e-02,  1.7373e-01],\n",
            "         [-2.4709e-01, -4.1842e-01, -6.1281e-02,  ..., -3.3752e-01,\n",
            "          -2.4293e-01, -1.0105e-02]],\n",
            "\n",
            "        [[-2.5697e-01,  3.5329e-01,  4.8139e-01,  ..., -4.3071e-01,\n",
            "           3.3572e-01,  1.2862e-01],\n",
            "         [ 1.0458e+00,  4.9262e-01,  8.6180e-01,  ...,  8.4476e-02,\n",
            "           4.6321e-01, -3.7395e-01],\n",
            "         [-1.8162e-01,  2.3864e-01,  8.1714e-01,  ..., -8.3285e-01,\n",
            "           6.6967e-01,  2.9754e-01],\n",
            "         ...,\n",
            "         [-1.3807e-01,  3.3029e-02,  6.5520e-02,  ..., -2.8278e-01,\n",
            "          -1.2559e-02, -9.5960e-02],\n",
            "         [-2.3732e-01, -5.7732e-01,  9.3384e-01,  ..., -2.9667e-01,\n",
            "          -1.7237e-01,  2.9914e-01],\n",
            "         [-5.5841e-01, -1.3858e-01,  4.3835e-01,  ..., -2.7621e-01,\n",
            "           3.2047e-01, -2.8787e-02]]], device='cuda:0'), pooler_output=tensor([[-0.7523, -0.2072,  0.4298,  ...,  0.3523, -0.5644,  0.8515],\n",
            "        [-0.6742, -0.3231, -0.1043,  ..., -0.0189, -0.5371,  0.6834],\n",
            "        [-0.6219, -0.4189, -0.7213,  ..., -0.6020, -0.4911,  0.6655],\n",
            "        ...,\n",
            "        [-0.3407, -0.1956, -0.5644,  ..., -0.6548, -0.3219,  0.4998],\n",
            "        [-0.5836, -0.2402, -0.7530,  ..., -0.7678, -0.4320,  0.8074],\n",
            "        [-0.7916, -0.4777, -0.9223,  ..., -0.8522, -0.5417,  0.8445]],\n",
            "       device='cuda:0'), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "# push the tensors to GPU\n",
        "sent_id = sent_id.to(device)\n",
        "mask = mask.to(device)\n",
        "target = target.to(device)\n",
        "\n",
        "# pass inputs to the model\n",
        "outputs = model(sent_id, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y4qy6zMxSUdR",
        "outputId": "649ae718-fd89-4d91-9d61-ce70af58699a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.1262, -1.1553, -1.0195],\n",
            "        [-1.3713, -0.9481, -1.0252],\n",
            "        [-1.2439, -1.0604, -1.0067],\n",
            "        [-1.2744, -1.0041, -1.0384],\n",
            "        [-1.3092, -1.0532, -0.9646],\n",
            "        [-1.2578, -1.1593, -0.9113],\n",
            "        [-1.4535, -1.0280, -0.8952],\n",
            "        [-1.3746, -0.9759, -0.9937],\n",
            "        [-1.2696, -1.1008, -0.9508],\n",
            "        [-1.1823, -1.1310, -0.9923],\n",
            "        [-1.3763, -1.0299, -0.9405],\n",
            "        [-1.1990, -1.1463, -0.9658],\n",
            "        [-1.2960, -1.0313, -0.9947],\n",
            "        [-1.3382, -1.0543, -0.9435],\n",
            "        [-1.2784, -1.1132, -0.9339],\n",
            "        [-1.3531, -1.0433, -0.9435]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# understand outputs\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGLOQD6gSUgv",
        "outputId": "462d6baa-130c-4781-9fcd-62b6eb335f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 395,267 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "# no. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxLgSFesSUjl"
      },
      "outputs": [],
      "source": [
        "#Define Optimizer and Loss function\n",
        "## Import AdamW optimizer\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Create the AdamW optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5,weight_decay=0.03)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "vKjcPr1hSUmd",
        "outputId": "118b8b0a-88e8-4e18-8baa-a544f10cc39f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# understand the class distribution\n",
        "keys=['0','1','2']\n",
        "\n",
        "# set figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "# plot bat chart\n",
        "plt.bar(keys,class_counts)\n",
        "\n",
        "# set title\n",
        "plt.title('Class Distribution')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxO9-n7cSUpH",
        "outputId": "eb7301ed-dc0b-4ac5-afb1-67f78da7a3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [2.85197191 2.10234966 0.46004357]\n"
          ]
        }
      ],
      "source": [
        "#library for array processing\n",
        "import numpy as np\n",
        "\n",
        "#library for computing class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Update to use the new API\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
        "\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qwZPjL6Hke3"
      },
      "outputs": [],
      "source": [
        "# converting a list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# transfer to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQpM92S3HkiH",
        "outputId": "cb4bb555-228b-4965-ea12-ad94db5ee7ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(1.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#compute the loss\n",
        "loss = cross_entropy(outputs, target)\n",
        "print(\"Loss:\",loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT4-8PvtHkk5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "# compute time in hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    # round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds = elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7ta01lhIP9E"
      },
      "outputs": [],
      "source": [
        "#define a function for training the model\n",
        "def train():\n",
        "\n",
        "  print(\"\\nTraining.....\")\n",
        "\n",
        "  #set the model on training phase - Dropout layers are activated\n",
        "  model.train()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds=[]\n",
        "\n",
        "  #for every batch\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Progress update after every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids\n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Always clear any previously calculated gradients before performing a\n",
        "    # backward pass. PyTorch doesn't do this automatically.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Perform a forward pass. This returns the model predictions\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    #compute the loss between actual and predicted values\n",
        "    loss =  cross_entropy(preds, labels)\n",
        "\n",
        "    # Accumulate the training loss over all of the batches so that we can\n",
        "    # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "    # single value; the `.item()` function just returns the Python value\n",
        "    # from the tensor.\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # Perform a backward pass to calculate the gradients.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "    # modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    #The model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    #Accumulate the model predictions of each batch\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  #compute the training loss of a epoch\n",
        "  avg_loss     = total_loss / len(train_dataloader)\n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpTmJ7BWOAgA"
      },
      "outputs": [],
      "source": [
        "#define a function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "  print(\"\\nEvaluating.....\")\n",
        "\n",
        "  #set the model on training phase - Dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize the loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  #for each batch\n",
        "  for step,batch in enumerate(validation_dataloader):\n",
        "\n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids\n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # Perform a forward pass. This returns the model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # Check if preds is a tuple and extract the correct element\n",
        "      if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "      #compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      # Accumulate the validation loss over all of the batches so that we can\n",
        "      # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "      # single value; the `.item()` function just returns the Python value\n",
        "      # from the tensor.\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      #The model predictions are stored on GPU. So, push it to CPU\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "\n",
        "      #Accumulate the model predictions of each batch\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  #compute the validation loss of a epoch\n",
        "  avg_loss = total_loss / len(validation_dataloader)\n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GcQsR6RIOMWk",
        "outputId": "e6176a0c-a861-4d22-b43f-290d7ffa3abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "....... epoch 1 / 3 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    297.    Elapsed: 0:00:30.\n",
            "  Batch    80  of    297.    Elapsed: 0:01:00.\n",
            "  Batch   120  of    297.    Elapsed: 0:01:30.\n",
            "  Batch   160  of    297.    Elapsed: 0:02:01.\n",
            "  Batch   200  of    297.    Elapsed: 0:02:32.\n",
            "  Batch   240  of    297.    Elapsed: 0:03:04.\n",
            "  Batch   280  of    297.    Elapsed: 0:03:36.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.826\n",
            "Validation Loss: 1.039\n",
            "\n",
            "....... epoch 2 / 3 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    297.    Elapsed: 0:00:31.\n",
            "  Batch    80  of    297.    Elapsed: 0:01:03.\n",
            "  Batch   120  of    297.    Elapsed: 0:01:35.\n",
            "  Batch   160  of    297.    Elapsed: 0:02:07.\n",
            "  Batch   200  of    297.    Elapsed: 0:02:38.\n",
            "  Batch   240  of    297.    Elapsed: 0:03:10.\n",
            "  Batch   280  of    297.    Elapsed: 0:03:42.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.647\n",
            "Validation Loss: 1.069\n",
            "\n",
            "....... epoch 3 / 3 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    297.    Elapsed: 0:00:32.\n",
            "  Batch    80  of    297.    Elapsed: 0:01:03.\n",
            "  Batch   120  of    297.    Elapsed: 0:01:35.\n",
            "  Batch   160  of    297.    Elapsed: 0:02:07.\n",
            "  Batch   200  of    297.    Elapsed: 0:02:39.\n",
            "  Batch   240  of    297.    Elapsed: 0:03:10.\n",
            "  Batch   280  of    297.    Elapsed: 0:03:42.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.413\n",
            "Validation Loss: 1.418\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Train the Model\n",
        "\n",
        "#Assign the initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "#create a empty list to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n....... epoch {:} / {:} .......'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    #accumulate training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv4H0XymOWUt",
        "outputId": "13a1d4b7-5394-427d-f134-17cb2f6bd6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-93-d5e1bb6310d2>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "#load weights of the best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8EO2K9fJHkyc",
        "outputId": "48054d12-9673-4895-bc5f-c4b24f52ce0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating.....\n",
            "1.039048896594481\n"
          ]
        }
      ],
      "source": [
        "# get the model predictions on the validation data\n",
        "# returns 2 elements- Validation loss and Predictions\n",
        "valid_loss, preds = evaluate()\n",
        "print(valid_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUa15KNVHk4P"
      },
      "outputs": [],
      "source": [
        "# Converting the log(probabities) into a classes\n",
        "# Choosing index of a maximum value as class\n",
        "y_pred = np.argmax(preds,axis=1)\n",
        "# actual labels\n",
        "y_true = validation_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GmCa3kFHk6x",
        "outputId": "8969104b-50c8-43e1-9bdf-aa7b3db8eae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.52      0.33        62\n",
            "           1       0.37      0.30      0.33        84\n",
            "           2       0.79      0.68      0.73       382\n",
            "\n",
            "    accuracy                           0.60       528\n",
            "   macro avg       0.47      0.50      0.47       528\n",
            "weighted avg       0.66      0.60      0.62       528\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tsnn2XJTf8i",
        "outputId": "eafe1eea-35a5-4719-d864-14079a2000f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro F1-Score: 0.465\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "macro_f1 = f1_score(y_true, y_pred, average='macro').round(3)\n",
        "print(f\"Macro F1-Score: {macro_f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer, BertConfig\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "        self.fc2 = nn.Linear(512, 3)  # Adjust the output size based on your number of classes\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        outputs = self.bert(sent_id, attention_mask=mask)\n",
        "        all_hidden_states = outputs.last_hidden_state\n",
        "        cls_hidden_state = all_hidden_states[:, 0]\n",
        "        x = self.fc1(cls_hidden_state)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Initialize BERT model and tokenizer\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Initialize the classifier with the BERT model\n",
        "model = Classifier(bert_model)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Load the saved weights\n",
        "model_path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze()\n",
        "        }\n",
        "\n",
        "def preprocessor(text):\n",
        "    # Preprocessing function implementation\n",
        "\n",
        "    # Expand contractions\n",
        "    text = contractions.fix(text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Replace numbers\n",
        "    text = re.sub(r'\\d+', '<num>', text)\n",
        "\n",
        "    # Replace emails and mentions\n",
        "    text = re.sub(r'\\S+@\\S+', '<email>', text)  # replace emails with <email>\n",
        "    text = re.sub(r'@\\w+', '<mention>', text)   # replace mentions with <mention>\n",
        "\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "    # Removes emojis and certain symbols\n",
        "    text = re.sub(r'[^\\w\\s,]', '', text)\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Replace numbers with a placeholder\n",
        "    text = re.sub(r'\\d+', '<num>', text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatize tokens\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', \" \".join(tokens)).strip()\n",
        "\n",
        "    return text\n",
        "    pass\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_df['preprocessed_text'] = test_df['text'].apply(preprocessor)\n",
        "\n",
        "# Create DataLoader for the test set\n",
        "test_dataset = TestDataset(test_df['preprocessed_text'].tolist(), tokenizer, max_length=250)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_test(model, dataloader, device):\n",
        "    print(\"\\nEvaluating.....\")\n",
        "    model.eval()\n",
        "    total_preds = []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = {key: value.to(device) for key, value in batch.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
        "            logits = outputs\n",
        "            preds = logits.detach().cpu().numpy()\n",
        "            total_preds.append(preds)\n",
        "\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "    return total_preds\n",
        "\n",
        "# Get predictions\n",
        "predictions = evaluate_test(model, test_dataloader, device)\n",
        "\n",
        "# Add predictions to the dataframe\n",
        "test_df['sentiment'] = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Rename and drop columns\n",
        "test_df.rename(columns={'unique_hash':'id'}, inplace=True)\n",
        "test_df = test_df[['id', 'sentiment']]\n",
        "\n",
        "# Save results to a new CSV file\n",
        "test_df.to_csv('test_predictions.csv', index=False)\n",
        "\n",
        "# Print the first few rows of the result\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH6sNfA1g5Es",
        "outputId": "621586a3-889c-4a2e-ca1a-3c04afe0a4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "<ipython-input-99-524fa3d97f9e>:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating.....\n",
            "                                         id  sentiment\n",
            "0  9e9a8166b84114aca147bf409f6f956635034c08          2\n",
            "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a          0\n",
            "2  50b6d851bcff4f35afe354937949e9948975adf7          2\n",
            "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae          2\n",
            "4  8b37d169dee5bdae27060949242fb54feb6a7f7f          2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C5P93clXjR1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71df7a084c6a4c438c02ccd0854c0f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3548548d8d494297bd1ba729d3e7769b",
              "IPY_MODEL_b401a3e63d1d40c29b3f89297dfa9b0e",
              "IPY_MODEL_315691cab3134145830f41eada8a0a78"
            ],
            "layout": "IPY_MODEL_dfae2fce887e407eafc97e1685dd541c"
          }
        },
        "3548548d8d494297bd1ba729d3e7769b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bb6bd6c22c4df4bbfeedf8dbf27f3f",
            "placeholder": "​",
            "style": "IPY_MODEL_18a0874dfec14ea090dc1ac7f5380370",
            "value": "100%"
          }
        },
        "b401a3e63d1d40c29b3f89297dfa9b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99e9dee44f574e31b6942d44fd27d19b",
            "max": 5279,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_962f96b0369141bd93f33a2fd0eb4527",
            "value": 5279
          }
        },
        "315691cab3134145830f41eada8a0a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03da03df17b34177878828645ccffc91",
            "placeholder": "​",
            "style": "IPY_MODEL_9a2b0ff1afaf4bd097efaf9fece6d62b",
            "value": " 5279/5279 [00:15&lt;00:00, 427.82it/s]"
          }
        },
        "dfae2fce887e407eafc97e1685dd541c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bb6bd6c22c4df4bbfeedf8dbf27f3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18a0874dfec14ea090dc1ac7f5380370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99e9dee44f574e31b6942d44fd27d19b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962f96b0369141bd93f33a2fd0eb4527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03da03df17b34177878828645ccffc91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2b0ff1afaf4bd097efaf9fece6d62b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}